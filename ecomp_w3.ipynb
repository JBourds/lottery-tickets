{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6278b811-d488-4ff7-8a1d-23fd73d96c97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 21:14:24.866071: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-14 21:14:24.943281: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-14 21:14:24.976359: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-14 21:14:25.134519: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-14 21:14:30.205444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'src.harness.evolution' from '/gpfs1/home/j/b/jbourde2/lottery-tickets/src/harness/evolution.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.harness import architecture as arch\n",
    "from src.harness import evolution as evo\n",
    "from src.harness import utils\n",
    "\n",
    "import copy\n",
    "from enum import Enum\n",
    "import functools\n",
    "from importlib import reload\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "import multiprocess as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from typing import Any, Callable, Dict, Iterable, List, Literal, Set, Tuple\n",
    "\n",
    "reload(arch)\n",
    "reload(evo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "492ca0a2-4930-4486-b3f4-4fa10d0e996d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 21:14:40.684746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:66:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "architecture = arch.Architecture(\"lenet\", \"mnist\")\n",
    "\n",
    "model_features = [\n",
    "    evo.ModelFeatures.layer_sparsity, \n",
    "    evo.ModelFeatures.magnitude,\n",
    "    evo.ModelFeatures.random,\n",
    "    functools.partial(evo.ModelFeatures.synaptic_flow, loss_fn=keras.losses.CategoricalCrossentropy()),\n",
    "]\n",
    "arch_feature_selectors = [\n",
    "    evo.ArchFeatures.layer_num,\n",
    "    evo.ArchFeatures.layer_ohe,\n",
    "    evo.ArchFeatures.layer_prop_params,\n",
    "]\n",
    "\n",
    "individual = evo.Individual(\"lenet\", \"mnist\", model_features, arch_feature_selectors, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9c5a48-06c6-4c70-a5fc-1e285c39b820",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "Generation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/j/b/jbourde2/.conda/envs/lt/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731636890.334676  170581 service.cc:146] XLA service 0x2b6f10001010 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731636890.334832  170581 service.cc:154]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-11-14 21:14:50.372704: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-14 21:14:50.564389: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "I0000 00:00:1731636891.591281  170581 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x2b6e8f9e5300> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x2b6e8fef5a80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/j/b/jbourde2/.conda/envs/lt/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 4 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2\n",
      "Run 2\n",
      "Generation 1\n",
      "Generation 2\n",
      "Run 3\n",
      "Generation 1\n",
      "Generation 2\n"
     ]
    }
   ],
   "source": [
    "num_runs = 3\n",
    "\n",
    "model_feature_selectors = [\n",
    "    evo.ModelFeatures.layer_sparsity, \n",
    "    evo.ModelFeatures.magnitude,\n",
    "    evo.ModelFeatures.random,\n",
    "    functools.partial(evo.ModelFeatures.synaptic_flow, loss_fn=keras.losses.CategoricalCrossentropy()),\n",
    "]\n",
    "arch_feature_selectors = [\n",
    "    evo.ArchFeatures.layer_num,\n",
    "    evo.ArchFeatures.layer_ohe,\n",
    "    evo.ArchFeatures.layer_prop_params,\n",
    "]\n",
    "\n",
    "layers = []\n",
    "\n",
    "individual_constructor = functools.partial(\n",
    "    evo.Individual, \n",
    "    architecture_name=\"lenet\",\n",
    "    dataset_name=\"mnist\",\n",
    "    model_feature_selectors=model_feature_selectors,\n",
    "    arch_feature_selectors=arch_feature_selectors,\n",
    "    layers=layers,\n",
    ")\n",
    "\n",
    "objectives = [\n",
    "    (evo.Target.MAXIMIZE, lambda x: 1, evo.Individual.eval_accuracy),\n",
    "    (evo.Target.MINIMIZE, lambda x: 1, evo.Individual.sparsity),\n",
    "]\n",
    "\n",
    "rate_func = lambda n: 0.5\n",
    "scale_func = lambda n: 1 / np.sqrt(n + 1)\n",
    "mutations = [\n",
    "    functools.partial(evo.Individual.get_annealing_mutate(), rate=rate_func, scale=scale_func),\n",
    "    evo.Individual.update_phenotype,\n",
    "]\n",
    "    \n",
    "genome_metric_callbacks = [\n",
    "]\n",
    "kwargs = {\n",
    "    \"num_generations\": 2,\n",
    "    \"archive_size\": 10,\n",
    "    \"population_size\": 10,\n",
    "    \"fronts_to_consider\": 2,\n",
    "    \"tournament_size\": 4,\n",
    "    \"num_tournament_winners\": 2,\n",
    "    \"individual_constructor\": individual_constructor,\n",
    "    \"objectives\": objectives,\n",
    "    \"mutations\": mutations,\n",
    "    \"crossover\": evo.Individual.crossover,\n",
    "    \"genome_metric_callbacks\": genome_metric_callbacks,\n",
    "}\n",
    "\n",
    "all_genome_metrics = []\n",
    "all_objective_metrics = []\n",
    "all_archives = []\n",
    "for run in range(num_runs):\n",
    "    print(f\"Run {run + 1}\")\n",
    "    genome_metrics, objective_metrics, archive = evo.nsga2(**kwargs)\n",
    "    all_genome_metrics.append(genome_metrics)\n",
    "    all_objective_metrics.append(objective_metrics)\n",
    "    all_archives.append(archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c91e6e08-f138-45e0-a75b-86cc97e5d85d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'objective_0_value': array([[0.08, 0.08],\n",
       "         [0.06, 0.08],\n",
       "         [0.03, 0.07],\n",
       "         [0.07, 0.08],\n",
       "         [0.08, 0.11],\n",
       "         [0.14, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.06, 0.08],\n",
       "         [0.08, 0.07],\n",
       "         [0.08, 0.08]]),\n",
       "  'objective_1_value': array([[2.73808184e-04, 4.59097558e-03],\n",
       "         [6.56689547e-02, 1.31277897e-04],\n",
       "         [1.17778778e-01, 2.74183264e-03],\n",
       "         [1.18176362e-01, 1.19425378e-02],\n",
       "         [4.09962117e-02, 3.66227823e-02],\n",
       "         [1.11304902e-01, 2.85435655e-02],\n",
       "         [7.32155583e-03, 5.25111586e-05],\n",
       "         [8.33127039e-02, 1.12523911e-05],\n",
       "         [1.17782529e-01, 1.59371366e-02],\n",
       "         [1.17790030e-01, 6.00127527e-05]]),\n",
       "  'objective_0_range': array([1., 1.]),\n",
       "  'objective_1_range': array([1., 1.])},\n",
       " {'objective_0_value': array([[0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08]]),\n",
       "  'objective_1_value': array([[0.01576835, 0.02627433],\n",
       "         [0.00528862, 0.0882225 ],\n",
       "         [0.00528862, 0.11553955],\n",
       "         [0.00528862, 0.06141555],\n",
       "         [0.00528862, 0.04695998],\n",
       "         [0.11674731, 0.04010727],\n",
       "         [0.01921533, 0.10291062],\n",
       "         [0.05786355, 0.07319305],\n",
       "         [0.11779003, 0.11781254],\n",
       "         [0.00528862, 0.00416338]]),\n",
       "  'objective_0_range': array([1., 1.]),\n",
       "  'objective_1_range': array([1., 1.])},\n",
       " {'objective_0_value': array([[0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08],\n",
       "         [0.08, 0.08]]),\n",
       "  'objective_1_value': array([[0.07597614, 0.16234575],\n",
       "         [0.13755298, 0.04672743],\n",
       "         [0.03698286, 0.16089044],\n",
       "         [0.20456097, 0.14506958],\n",
       "         [0.10029631, 0.28362777],\n",
       "         [0.16561644, 0.11017216],\n",
       "         [0.21614718, 0.10995837],\n",
       "         [0.2465924 , 0.20953078],\n",
       "         [0.05927009, 0.22197967],\n",
       "         [0.20455722, 0.21096733]]),\n",
       "  'objective_0_range': array([1., 1.]),\n",
       "  'objective_1_range': array([1., 1.])}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_objective_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e07cd4-57fc-4023-92c2-7dbfd80c5347",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"2\".split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a71ec-df6b-4f6c-9443-6cf106107518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lt",
   "language": "python",
   "name": "lt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
