{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ae830d3-ea46-4835-949b-8cc6522b7b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Version: 1.26.4\n",
      "Tensorflow Version: 2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "from tensorflow import keras\n",
    "import numpy.typing as npt\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"Numpy Version:\", np.__version__)\n",
    "print(\"Tensorflow Version:\", tf.__version__)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Generator, List, Tuple\n",
    "\n",
    "from src.harness import architecture as arch\n",
    "from src.harness import dataset as ds\n",
    "from src.harness import history as hist\n",
    "\n",
    "from src.metrics.features import *\n",
    "from src.metrics.synflow import compute_synflow_per_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a917686-f38a-4129-a2a2-a97a604f093c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/j/b/jbourde2/lottery-tickets/experiments/11-04-2024/lenet_mnist_0_seed_5_experiments_1_batches_0.025_default_sparsity_lm_pruning_20241102-111614\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.path.expanduser(\"~\"), \"lottery-tickets/experiments/11-04-2024/\")\n",
    "experiment_directories = os.listdir(path)\n",
    "e = os.path.join(path, experiment_directories[1])\n",
    "print(e)\n",
    "experiments = list(hist.get_experiments(e))\n",
    "e0 = experiments[0]\n",
    "for trial in experiments[0]:\n",
    "    trial.seed_weights = lambda x: x\n",
    "    pass\n",
    "\n",
    "a = arch.Architecture(\"lenet\", \"mnist\")\n",
    "model = a.get_model_constructor()()\n",
    "model.set_weights([m * w for m, w in zip(trial.masks, trial.initial_weights)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4136c6f3-ecfe-4850-a446-b43283f97cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sparsity', 'size', 'l_size', 'l_rel_size', 'l_sparsity', 'lf_mean',\n",
       "       'lf_std', 'lf_prop_positive', 'li_mean', 'li_std', 'li_prop_positive',\n",
       "       'dense', 'bias', 'conv', 'output', 'wf_sign', 'wi_sign', 'wf_val',\n",
       "       'wi_val', 'wf_mag', 'wi_mag', 'wf_perc', 'wi_perc', 'wf_std', 'wi_std',\n",
       "       'w_mask', 'wf_synflow', 'wi_synflow', 'arch_lenet', 'dataset_mnist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90743cae-a5f7-4f82-85b9-e25e6185dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"weightabase.pkl\"\n",
    "merged_df = pd.read_pickle(df_path)\n",
    "# corrected_wdf = correct_class_imbalance(wdf)\n",
    "# merged_df = merge_dfs(tdf, ldf, corrected_wdf)\n",
    "# merged_df.to_pickle(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "875f115c-e341-4c0a-ba77-8970e7dedccc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23342691, 0.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[\"wi_mag\"].max(), merged_df[\"wi_mag\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d615738-634c-46a8-9c33-d1e745ddb502",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"norm_wi_mag\"] = merged_df[\"wi_mag\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efdb949-840e-412e-8936-e43985c26f9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Feature importance ovservations:\n",
    "\n",
    "- Mask & sign directly tell the model what the outcome is (sign == 0 rather than +/- 1) which gets it perfectly\n",
    "- The final measures for weights all get >93% accuracy, magnitude gets 98.14%\n",
    "- Measures of current sparsity get pretty high (layer and overall sparsity both ~78%)\n",
    "- The initial percentile a weight falls in gets 75% (wi_std gets much worse even though they are the same measure- perhaps the scale being between 0 and 1 makes it easier to train on?)\n",
    "- All the OHE and initial weight magnitude measures get 57.85% accuracy\n",
    "    - What is special about this number?\n",
    "    - Why are the initial metrics (including magnitude) so uninformative?\n",
    "        - Could a normalization scheme help this?\n",
    "    - Why does \"wi_std\" do worse than random chance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b7fdb79-e18f-460e-93be-a5e8fc3e2ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wf_sign\n",
       " 0.0    2623048\n",
       "-1.0    1328976\n",
       " 1.0    1292028\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[\"wf_sign\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ef7c50d3-c539-44ff-a063-484b30d845ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating meta mask model off the final weights\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 20:43:58.964395: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 20:43:58.964540: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 20:43:58.964638: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 20:43:59.006219: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 20:43:59.006343: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 20:43:59.006402: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16323/16388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9577 - loss: 0.1832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 20:44:09.988488: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 20:44:09.988776: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 20:44:09.988834: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 20:44:10.000835: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 20:44:10.001098: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 20:44:10.001156: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16388/16388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 783us/step - accuracy: 0.9579 - loss: 0.1827 - val_accuracy: 1.0000 - val_loss: 2.2399e-04\n",
      "Epoch 2/3\n",
      "\u001b[1m16388/16388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 775us/step - accuracy: 1.0000 - loss: 3.1697e-05 - val_accuracy: 1.0000 - val_loss: 4.9822e-06\n",
      "Epoch 3/3\n",
      "\u001b[1m16388/16388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 775us/step - accuracy: 1.0000 - loss: 3.2371e-07 - val_accuracy: 1.0000 - val_loss: 3.2796e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b635b506790>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_features = [\"l_sparsity\", \"l_rel_size\", \"lf_prop_positive\", \"wf_std\", \"wf_perc\", \"wf_synflow\", \"wf_sign\", \"dense\", \"bias\", \"conv\", \"output\"]\n",
    "fX, fY = featurize_db(merged_df, f_features)\n",
    "\n",
    "print(\"Creating meta mask model off the final weights\")\n",
    "f_meta = create_meta(fX[0].shape)\n",
    "f_meta.fit(fX, fY, epochs=3, batch_size=256, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2204b26e-3fab-4b06-bbdc-38d6ff4f3e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating meta mask model off the initial weights\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 15:24:41.700584: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 15:24:41.700714: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 15:24:41.700771: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 15:24:41.736803: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 15:24:41.736927: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 15:24:41.736985: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16335/16388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.7388 - loss: 0.5134"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 15:24:52.044018: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 15:24:52.044331: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 15:24:52.044399: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 15:24:52.056988: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 15:24:52.057278: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n",
      "2025-02-22 15:24:52.057343: W tensorflow/core/util/util.cc:161] Not handling type DT_DOUBLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16388/16388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 743us/step - accuracy: 0.7389 - loss: 0.5133 - val_accuracy: 0.8183 - val_loss: 0.4447\n",
      "Epoch 2/3\n",
      "\u001b[1m16388/16388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 739us/step - accuracy: 0.7807 - loss: 0.4554 - val_accuracy: 0.8183 - val_loss: 0.4445\n",
      "Epoch 3/3\n",
      "\u001b[1m16388/16388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 737us/step - accuracy: 0.7805 - loss: 0.4554 - val_accuracy: 0.8183 - val_loss: 0.4445\n"
     ]
    }
   ],
   "source": [
    "i_features = [\"l_sparsity\", \"l_rel_size\", \"li_prop_positive\", \"wi_std\", \"wi_perc\", \"wi_synflow\", \"wi_sign\", \"dense\", \"bias\", \"conv\", \"output\"]\n",
    "\n",
    "i_features = [\"l_sparsity\"]\n",
    "iX, iY = featurize_db(merged_df, i_features)\n",
    "\n",
    "print(\"Creating meta mask model off the initial weights\")\n",
    "i_meta = create_meta(iX[0].shape)\n",
    "history = i_meta.fit(iX, iY, epochs=3, batch_size=256, validation_split=0.2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d929c964-f45f-4a9f-bbd2-f9d625dec62b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0911 - loss: 2.3523\n",
      "Step 0 accuracy: 9.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/j/b/jbourde2/.conda/envs/lt/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/tmp/ipykernel_2941/4018827003.py:56: RuntimeWarning: invalid value encountered in divide\n",
      "  w_std = [(w - l_mean) / l_std for w, l_mean, l_std in zip(l_std, l_mean, masked_weights)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_607\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (266610, 11)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(266610, 11), dtype=float64)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[187], line 47\u001b[0m\n\u001b[1;32m     41\u001b[0m         model\u001b[38;5;241m.\u001b[39mset_weights([w \u001b[38;5;241m*\u001b[39m m \u001b[38;5;28;01mfor\u001b[39;00m w, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(original_weights, masks)])\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m masks, accuracies\n\u001b[0;32m---> 47\u001b[0m masks, accuracies \u001b[38;5;241m=\u001b[39m make_meta_mask(i_meta, make_x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlenet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m50\u001b[39m)\n",
      "Cell \u001b[0;32mIn[187], line 39\u001b[0m, in \u001b[0;36mmake_meta_mask\u001b[0;34m(meta, make_x, architecture, dataset, steps)\u001b[0m\n\u001b[1;32m     37\u001b[0m X \u001b[38;5;241m=\u001b[39m make_x(architecture, model, masks)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Predict and replace existing mask\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m mask_pred \u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mpredict(X, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     40\u001b[0m masks \u001b[38;5;241m=\u001b[39m update_masks(mask_pred)\n\u001b[1;32m     41\u001b[0m model\u001b[38;5;241m.\u001b[39mset_weights([w \u001b[38;5;241m*\u001b[39m m \u001b[38;5;28;01mfor\u001b[39;00m w, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(original_weights, masks)])\n",
      "File \u001b[0;32m~/.conda/envs/lt/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/lt/lib/python3.11/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_607\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (266610, 11)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(266610, 11), dtype=float64)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "masks, accuracies = make_meta_mask(i_meta, make_x, \"lenet\", \"mnist\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f99cbb-78d2-419e-a443-79637b811d33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lt",
   "language": "python",
   "name": "lt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
