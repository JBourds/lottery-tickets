{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "experiments.ipynb\n",
    "\n",
    "File for running lottery ticket experiments.\n",
    "\n",
    "Authors: Jordan Bourdeau, Casey Forey\n",
    "Date Created: 3/8/24\n",
    "\"\"\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "import copy\n",
    "import functools\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "from tensorflow_model_optimization.sparsity.keras import ConstantSparsity, PolynomialDecay, prune_low_magnitude\n",
    "\n",
    "import src.harness.constants as C\n",
    "import src.harness.dataset as dataset\n",
    "import src.harness.experiment as experiment\n",
    "import src.harness.model as mod\n",
    "import src.harness.paths as paths\n",
    "import src.harness.pruning as prune\n",
    "import src.harness.training as train\n",
    "import src.harness.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mod)\n",
    "reload(prune)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = dataset.load_and_process_mnist()\n",
    "\n",
    "num_epochs: int = 10\n",
    "input_shape: tuple = X_train[0].shape\n",
    "num_classes: int = 10\n",
    "batch_size: int = len(X_train)\n",
    "\n",
    "num_train_samples: int = X_train.shape[0]\n",
    "\n",
    "# Make pruning parameters\n",
    "target_sparsity: float = 0.01\n",
    "step_pruning_percent: float = 0.2\n",
    "end_step: int = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * num_epochs\n",
    "frequency: int = 1\n",
    "create_pruning_parameters: callable = functools.partial(prune.create_pruning_parameters, target_sparsity, 0, end_step, frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mod)\n",
    "reload(paths)\n",
    "reload(train)\n",
    "\n",
    "make_lenet: callable = functools.partial(mod.create_lenet_300_100, input_shape, num_classes)\n",
    "\n",
    "# Hardcoded for now until actual experiment code is done\n",
    "for seed in range(2):\n",
    "    utils.set_seed(seed)\n",
    "    # Make models\n",
    "    model: keras.Model = make_lenet()\n",
    "    mask_model: keras.Model = mod.create_masked_nn(mod.create_pruned_lenet, input_shape, num_classes, create_pruning_parameters)   \n",
    "\n",
    "    mod.save_model(model, seed, 0, initial=True)\n",
    "    \n",
    "    # We aren't actually doing any pruning right now\n",
    "    for pruning_step in range(2):\n",
    "        loss_fn: tf.keras.losses.Loss = C.LOSS_FUNCTION()\n",
    "        accuracy_metric: tf.keras.metrics.Metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "        # Sanity Check\n",
    "        test_loss, test_accuracy = train.test_step(model, X_test, Y_test, loss_fn, accuracy_metric)\n",
    "        print(f'\\nModel {seed}\\nStarting Test Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}\\n')\n",
    "\n",
    "        trained_model, pruned_mask_model, training_round = train.train(seed, pruning_step, model, mask_model, dataset.load_and_process_mnist, batch_size=C.BATCH_SIZE)\n",
    "\n",
    "        print(f'\\nTook {np.sum(training_round.test_accuracies != 0)} / {C.TRAINING_EPOCHS} epochs')\n",
    "        print(f'Ended with a best training accuracy of {np.max(training_round.train_accuracies) * 100:.2f}% and test accuracy of training accuracy of {np.max(training_round.test_accuracies) * 100:.2f}%')\n",
    "\n",
    "        print(f'Test Accuracies:')\n",
    "        print(training_round.test_accuracies)\n",
    "        print(f'Training Accuracies:')\n",
    "        print(training_round.train_accuracies)\n",
    "\n",
    "        # Get test parameters\n",
    "        test_loss, test_accuracy = train.test_step(trained_model, X_test, Y_test, loss_fn, accuracy_metric)\n",
    "        print(f'\\nTest Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
