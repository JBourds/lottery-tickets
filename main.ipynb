{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "main.ipynb\n",
    "\n",
    "Main file for recreating lottery ticket experiments done in randomly initialized dense neural networks.\n",
    "\n",
    "Authors: Jordan Bourdeau, Casey Forey\n",
    "Date Created: 3/8/24\n",
    "\"\"\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "import functools\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.harness import constants as C\n",
    "from src.harness.dataset import download_data, load_and_process_mnist\n",
    "from src.harness.experiment import experiment\n",
    "from src.harness.model import create_model, LeNet300, load_model\n",
    "from src.harness.pruning import prune_by_percent\n",
    "from src.harness.training import train\n",
    "from src.lottery_ticket.foundations import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "Pruning Step 0\n",
      "Iteration 1/10, Loss: 2.3550610542297363\n",
      "Iteration 2/10, Loss: 2.271308422088623\n",
      "Iteration 3/10, Loss: 2.199246883392334\n",
      "Iteration 4/10, Loss: 2.1306018829345703\n",
      "Iteration 5/10, Loss: 2.0620598793029785\n",
      "Iteration 6/10, Loss: 1.9923481941223145\n",
      "Iteration 7/10, Loss: 1.9212288856506348\n",
      "Iteration 8/10, Loss: 1.8489227294921875\n",
      "Iteration 9/10, Loss: 1.7759305238723755\n",
      "Iteration 10/10, Loss: 1.7027148008346558\n",
      "Pruning Step 1\n",
      "Iteration 1/10, Loss: 2.288278341293335\n",
      "Iteration 2/10, Loss: 2.2094662189483643\n",
      "Iteration 3/10, Loss: 2.1392059326171875\n",
      "Iteration 4/10, Loss: 2.0713226795196533\n",
      "Iteration 5/10, Loss: 2.003674030303955\n",
      "Iteration 6/10, Loss: 1.9356462955474854\n",
      "Iteration 7/10, Loss: 1.8672055006027222\n",
      "Iteration 8/10, Loss: 1.798560380935669\n",
      "Iteration 9/10, Loss: 1.7300267219543457\n",
      "Iteration 10/10, Loss: 1.6620514392852783\n",
      "Pruning Step 2\n",
      "Iteration 1/10, Loss: 2.2270307540893555\n",
      "Iteration 2/10, Loss: 2.152894973754883\n",
      "Iteration 3/10, Loss: 2.084874153137207\n",
      "Iteration 4/10, Loss: 2.018730640411377\n",
      "Iteration 5/10, Loss: 1.9530919790267944\n",
      "Iteration 6/10, Loss: 1.8876439332962036\n",
      "Iteration 7/10, Loss: 1.822447657585144\n",
      "Iteration 8/10, Loss: 1.7576384544372559\n",
      "Iteration 9/10, Loss: 1.6935791969299316\n",
      "Iteration 10/10, Loss: 1.630627989768982\n",
      "Pruning Step 3\n",
      "Iteration 1/10, Loss: 2.1632847785949707\n",
      "Iteration 2/10, Loss: 2.0940816402435303\n",
      "Iteration 3/10, Loss: 2.0296998023986816\n",
      "Iteration 4/10, Loss: 1.9671326875686646\n",
      "Iteration 5/10, Loss: 1.9052965641021729\n",
      "Iteration 6/10, Loss: 1.843860387802124\n",
      "Iteration 7/10, Loss: 1.782880425453186\n",
      "Iteration 8/10, Loss: 1.722574234008789\n",
      "Iteration 9/10, Loss: 1.6632325649261475\n",
      "Iteration 10/10, Loss: 1.6052213907241821\n",
      "Pruning Step 4\n",
      "Iteration 1/10, Loss: 2.087902784347534\n",
      "Iteration 2/10, Loss: 2.0233914852142334\n",
      "Iteration 3/10, Loss: 1.9623942375183105\n",
      "Iteration 4/10, Loss: 1.9034619331359863\n",
      "Iteration 5/10, Loss: 1.8458468914031982\n",
      "Iteration 6/10, Loss: 1.789257526397705\n",
      "Iteration 7/10, Loss: 1.733679175376892\n",
      "Iteration 8/10, Loss: 1.6791613101959229\n",
      "Iteration 9/10, Loss: 1.6257814168930054\n",
      "Iteration 10/10, Loss: 1.5736298561096191\n",
      "Pruning Step 5\n",
      "Iteration 1/10, Loss: 2.0421864986419678\n",
      "Iteration 2/10, Loss: 1.9856550693511963\n",
      "Iteration 3/10, Loss: 1.930667757987976\n",
      "Iteration 4/10, Loss: 1.8767157793045044\n",
      "Iteration 5/10, Loss: 1.8236405849456787\n",
      "Iteration 6/10, Loss: 1.7714123725891113\n",
      "Iteration 7/10, Loss: 1.720184087753296\n",
      "Iteration 8/10, Loss: 1.6700654029846191\n",
      "Iteration 9/10, Loss: 1.6211752891540527\n",
      "Iteration 10/10, Loss: 1.573574185371399\n"
     ]
    }
   ],
   "source": [
    "def run_experiment():\n",
    "    \"\"\"\n",
    "    Function used to run the full lottery ticket experiment.\n",
    "    \"\"\"\n",
    "    make_dataset: callable = load_and_process_mnist\n",
    "    train_model: callable = functools.partial(train, iterations=C.TEST_TRAINING_ITERATIONS)\n",
    "    prune_masks: callable = functools.partial(prune_by_percent, C.PRUNING_PERCENTS)\n",
    "\n",
    "    for i in range(C.NUM_MODELS):\n",
    "        print(f'Model {i + 1}')\n",
    "        make_model: callable = functools.partial(LeNet300, i)\n",
    "        experiment(make_dataset, make_model, train_model, prune_masks, C.TEST_PRUNING_STEPS)\n",
    "\n",
    "run_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
