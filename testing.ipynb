{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "testing.ipynb\n",
    "\n",
    "File for performing testing to implement lottery ticket experiments.\n",
    "\n",
    "Authors: Jordan Bourdeau, Casey Forey\n",
    "Date Created: 3/8/24\n",
    "\"\"\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "import functools\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "from tensorflow_model_optimization.sparsity.keras import ConstantSparsity, PolynomialDecay, prune_low_magnitude\n",
    "\n",
    "from src.harness.constants import Constants as C\n",
    "from src.harness.dataset import download_data, load_and_process_mnist\n",
    "from src.harness.model import save_model, load_model\n",
    "from src.harness.pruning import create_pruning_callbacks, create_pruning_parameters\n",
    "from src.harness.training import train, TrainingRound\n",
    "from src.harness.utils import count_params, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = load_and_process_mnist()\n",
    "\n",
    "num_epochs: int = 10\n",
    "batch_size: int = 60\n",
    "input_shape: tuple = X_train[0].shape\n",
    "num_classes: int = 10\n",
    "\n",
    "num_train_samples: int = X_train.shape[0]\n",
    "\n",
    "end_step: int = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * num_epochs\n",
    "\n",
    "pruning_parameters: dict = create_pruning_parameters(0.01, 0, end_step, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with the same architecture using all Keras components to check its accuracy with the same parameters\n",
    "def create_lenet_300_100(\n",
    "    input_shape: tuple[int, ...], \n",
    "    num_classes: int, \n",
    "    optimizer = C.OPTIMIZER,\n",
    "    ) -> keras.Model:\n",
    "    \"\"\"\n",
    "    Function for creating LeNet-300-100 model.\n",
    "\n",
    "    :param input_shape: Expected input shape for images.\n",
    "    :param num_classes: Number of potential classes to predict.\n",
    "    :param optimizer:   Optimizer to use for training.\n",
    "\n",
    "    :returns: Compiled LeNet-300-100 architecture.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Input(input_shape),\n",
    "        Dense(300, activation='relu', kernel_initializer=tf.initializers.GlorotUniform()),\n",
    "        Dense(100, activation='relu', kernel_initializer=tf.initializers.GlorotUniform()),\n",
    "        Dense(num_classes, activation='softmax', kernel_initializer=tf.initializers.GlorotUniform()),\n",
    "    ], name=\"LeNet-300-100\")\n",
    "\n",
    "    model.compile(\n",
    "        loss=keras.losses.CategoricalCrossentropy(), \n",
    "        optimizer=optimizer(), \n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def global_pruning_nn(\n",
    "    input_shape: tuple[int, ...], \n",
    "    num_classes: int, \n",
    "    pruning_parameters: dict,\n",
    "    optimizer = C.OPTIMIZER,\n",
    "    ) -> keras.Model:\n",
    "    \"\"\"\n",
    "    Function to define the architecture of a neural network model\n",
    "    following 300 100 architecture for MNIST dataset and using\n",
    "    provided parameter which are used to prune the model.\n",
    "    \n",
    "    :param input_shape:        Expected input shape for images.\n",
    "    :param num_classes:        Number of potential classes to predict.\n",
    "    :param pruning_parameters: Dictionary to be unpacked for the pruning schedule.\n",
    "    :param optimizer:          Optimizer to use for training.\n",
    "\n",
    "    :returns: Compiled LeNet-300-100 architecture with layerwise low magnitude pruning.\n",
    "    \"\"\"\n",
    "    model = sparsity.prune_low_magnitude(Sequential([\n",
    "        Input(input_shape),\n",
    "        Dense(300, activation='relu', kernel_initializer=tf.initializers.GlorotUniform()),\n",
    "        Dense(100, activation='relu', kernel_initializer=tf.initializers.GlorotUniform()),\n",
    "        Dense(num_classes, activation='softmax', kernel_initializer=tf.initializers.GlorotUniform())\n",
    "    ], name=\"Pruned_LeNet-300-100\"), **pruning_parameters)\n",
    "\n",
    "    model.compile(\n",
    "        loss=keras.losses.CategoricalCrossentropy(), \n",
    "        optimizer=optimizer(), \n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_mask_model(model: keras.Model):\n",
    "    \"\"\"\n",
    "    Function which performs layerwise initialization of a keras model's weights to all 1s\n",
    "    as an initialization step for masking.\n",
    "\n",
    "    :param model: Keras model being set to all 1s.\n",
    "    \"\"\"\n",
    "    for weights in model.trainable_weights:\n",
    "        weights.assign(\n",
    "            tf.ones_like(\n",
    "                input=weights,\n",
    "                dtype=tf.float32,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero parameters before training:\n",
      "266200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 1, 10), dtype=float32, numpy=\n",
       "array([[[0.03675784, 0.08286017, 0.15588324, ..., 0.10381736,\n",
       "         0.15198708, 0.05716838]],\n",
       "\n",
       "       [[0.0516306 , 0.10735245, 0.10834687, ..., 0.10771041,\n",
       "         0.16217342, 0.07541302]],\n",
       "\n",
       "       [[0.12167772, 0.10012673, 0.11473323, ..., 0.0871617 ,\n",
       "         0.11975257, 0.07545463]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.05520871, 0.07962444, 0.16368584, ..., 0.08866281,\n",
       "         0.10203359, 0.09554213]],\n",
       "\n",
       "       [[0.06297164, 0.0989567 , 0.13472585, ..., 0.10705641,\n",
       "         0.1076025 , 0.06750833]],\n",
       "\n",
       "       [[0.07248026, 0.08178942, 0.13388856, ..., 0.1040113 ,\n",
       "         0.0931598 , 0.09374413]]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.harness.experiment import ExperimentData\n",
    "from src.harness.training import test_step, train, train_one_step, training_loop, TrainingRound\n",
    "\n",
    "# Create model and masked model\n",
    "mask_model = global_pruning_nn(input_shape, num_classes, pruning_parameters)\n",
    "model: keras.Model = create_lenet_300_100(input_shape, num_classes)\n",
    "initialize_mask_model(mask_model)\n",
    "\n",
    "print(f'Nonzero parameters before training:')\n",
    "print(count_params(model)[1])\n",
    "\n",
    "experiment_data: ExperimentData = ExperimentData()\n",
    "model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer outside of the function\n",
    "optimizer = C.OPTIMIZER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test single step of training\n",
    "# loss, accuracy = train_one_step(model, mask_model, X_train, Y_train, optimizer)\n",
    "# print(f'Loss: {loss:.6f}, Accuracy: {accuracy:.6g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.3444080352783203\n",
      "Test Accuracy: 0.09109999984502792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 20:03:36.340773: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# Try getting test accuracies with `test_step`\n",
    "test_loss: tf.keras.metrics.Metric = C.LOSS_FUNCTION()\n",
    "test_accuracy: tf.keras.metrics.Metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "loss, accuracy = test_step(model, X_test, Y_test, test_loss, test_accuracy)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing `training_loop` function\n",
    "# epochs: int = 500\n",
    "# batch_size: int = len(X_train)\n",
    "# trained_model, training_round = training_loop(0, model, mask_model, load_and_process_mnist, epochs, batch_size, optimizer=optimizer)\n",
    "# print(f'Took {np.sum(training_round.test_accuracies != 0)} / {epochs} epochs')\n",
    "# print(f'Ended with a best training accuracy of {np.max(training_round.train_accuracies) * 100:.2f}% and test accuracy of training accuracy of {np.max(training_round.test_accuracies) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping initiated\n",
      "Directory 'models/model_0/trial0/weights' already exists.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Directory 'models/model_0/trial0/masks' already exists.\n"
     ]
    }
   ],
   "source": [
    "# Testing `train` function\n",
    "\n",
    "# Create model and masked model\n",
    "mask_model = global_pruning_nn(input_shape, num_classes, pruning_parameters)\n",
    "model: keras.Model = create_lenet_300_100(input_shape, num_classes)\n",
    "initialize_mask_model(mask_model)\n",
    "\n",
    "trained_model, pruned_mask_model, training_round = train(0, 0, model, mask_model, load_and_process_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.0927822589874268\n",
      "Test Accuracy: 0.6111000180244446\n"
     ]
    }
   ],
   "source": [
    "test_loss: tf.keras.metrics.Metric = C.LOSS_FUNCTION()\n",
    "test_accuracy: tf.keras.metrics.Metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "loss, accuracy = test_step(trained_model, X_test, Y_test, test_loss, test_accuracy)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Test Loss: 1.0927822589874268\n",
      "Test Accuracy: 0.6111000180244446\n"
     ]
    }
   ],
   "source": [
    "# Test loading the model back\n",
    "loaded_model: keras.Model = load_model(0, 0)\n",
    "\n",
    "loss, accuracy = test_step(loaded_model, X_test, Y_test, test_loss, test_accuracy)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero parameters after training:\n",
      "266610\n"
     ]
    }
   ],
   "source": [
    "print(f'Nonzero parameters after training:')\n",
    "print(count_params(model)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
