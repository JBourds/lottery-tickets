{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "testing.ipynb\n",
    "\n",
    "File for performing testing to implement lottery ticket experiments.\n",
    "\n",
    "Authors: Jordan Bourdeau, Casey Forey\n",
    "Date Created: 3/8/24\n",
    "\"\"\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "import functools\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "from tensorflow_model_optimization.sparsity.keras import ConstantSparsity, PolynomialDecay, prune_low_magnitude\n",
    "\n",
    "from src.harness.constants import Constants as C\n",
    "from src.harness.dataset import download_data, load_and_process_mnist\n",
    "from src.harness.experiment import ExperimentData\n",
    "from src.harness.model import create_lenet_300_100, create_masked_nn, create_pruned_lenet, save_model, load_model\n",
    "from src.harness.pruning import create_pruning_callbacks, create_pruning_parameters\n",
    "from src.harness.training import test_step, train, train_one_step, training_loop, TrainingRound\n",
    "from src.harness.utils import count_params, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = load_and_process_mnist()\n",
    "\n",
    "num_epochs: int = 10\n",
    "batch_size: int = 60\n",
    "input_shape: tuple = X_train[0].shape\n",
    "num_classes: int = 10\n",
    "\n",
    "num_train_samples: int = X_train.shape[0]\n",
    "\n",
    "end_step: int = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * num_epochs\n",
    "\n",
    "pruning_parameters: dict = create_pruning_parameters(0.01, 0, end_step, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with the same architecture using all Keras components to check its accuracy with the same parameters\n",
    "set_seed(0)\n",
    "\n",
    "model: keras.Model = create_lenet_300_100(input_shape, num_classes)\n",
    "model.summary()\n",
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_model: keras.Model = create_masked_nn(create_pruned_lenet, input_shape, num_classes, pruning_parameters)\n",
    "mask_model.summary()\n",
    "mask_model.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single step of training\n",
    "\n",
    "# Define the optimizer outside of the function\n",
    "optimizer = C.OPTIMIZER()\n",
    "\n",
    "# Create model and masked model\n",
    "model: keras.Model = create_lenet_300_100(input_shape, num_classes)\n",
    "mask_model: keras.Model = create_masked_nn(create_pruned_lenet, input_shape, num_classes, pruning_parameters)\n",
    "\n",
    "loss, accuracy = train_one_step(model, mask_model, X_train, Y_train, optimizer)\n",
    "print(f'Loss: {loss:.6f}, Accuracy: {accuracy:.6g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try getting test accuracies with `test_step`\n",
    "test_loss: tf.keras.metrics.Metric = C.LOSS_FUNCTION()\n",
    "test_accuracy: tf.keras.metrics.Metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "loss, accuracy = test_step(model, X_test, Y_test, test_loss, test_accuracy)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing `training_loop` function\n",
    "\n",
    "# Define the optimizer outside of the function\n",
    "optimizer = C.OPTIMIZER()\n",
    "\n",
    "epochs: int = 2\n",
    "\n",
    "# Create model and masked model\n",
    "model: keras.Model = create_lenet_300_100(input_shape, num_classes)\n",
    "mask_model: keras.Model = create_masked_nn(create_pruned_lenet, input_shape, num_classes, pruning_parameters)\n",
    "\n",
    "trained_model, training_round = training_loop(0, model, mask_model, load_and_process_mnist, epochs, batch_size, optimizer=optimizer)\n",
    "print(f'Took {np.sum(training_round.test_accuracies != 0)} / {epochs} epochs')\n",
    "print(f'Ended with a best training accuracy of {np.max(training_round.train_accuracies) * 100:.2f}% and test accuracy of {np.max(training_round.test_accuracies) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing `train` function\n",
    "\n",
    "# Create model and masked model\n",
    "model: keras.Model = create_lenet_300_100(input_shape, num_classes)\n",
    "mask_model: keras.Model = create_masked_nn(create_pruned_lenet, input_shape, num_classes, pruning_parameters)\n",
    "\n",
    "trained_model, pruned_mask_model, training_round = train(0, 0, model, mask_model, load_and_process_mnist)\n",
    "\n",
    "test_accuracy: tf.keras.metrics.Metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "print(f'Took {np.sum(training_round.test_accuracies != 0)} / {C.TRAINING_EPOCHS} epochs')\n",
    "print(f'Ended with a best training accuracy of {np.max(training_round.train_accuracies) * 100:.2f}% and test accuracy of training accuracy of {np.max(training_round.test_accuracies) * 100:.2f}%')\n",
    "\n",
    "loss, accuracy = test_step(trained_model, X_test, Y_test, test_loss, test_accuracy)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the model back\n",
    "loaded_model: keras.Model = load_model(0, 0)\n",
    "\n",
    "loss, accuracy = test_step(loaded_model, X_test, Y_test, test_loss, test_accuracy)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Nonzero parameters after training:')\n",
    "print(count_params(model)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
