{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "testing.ipynb\n",
    "\n",
    "File for performing testing to implement lottery ticket experiments.\n",
    "\n",
    "Authors: Jordan Bourdeau, Casey Forey\n",
    "Date Created: 3/8/24\n",
    "\"\"\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "import copy\n",
    "import functools\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "import src.harness.constants as C\n",
    "import src.harness.dataset as dataset\n",
    "import src.harness.experiment as experiment\n",
    "import src.harness.model as mod\n",
    "import src.harness.pruning as pruning\n",
    "import src.harness.rewind as rewind\n",
    "import src.harness.training as train\n",
    "import src.harness.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mod)\n",
    "reload(pruning)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = dataset.load_and_process_mnist()\n",
    "\n",
    "num_epochs: int = 10\n",
    "input_shape: tuple = X_train[0].shape\n",
    "num_classes: int = 10\n",
    "batch_size: int = len(X_train)\n",
    "\n",
    "num_train_samples: int = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mod)\n",
    "reload(utils)\n",
    "\n",
    "# Create a model with the same architecture using all Keras components to check its accuracy with the same parameters\n",
    "utils.set_seed(0)\n",
    "make_lenet: callable = functools.partial(mod.create_lenet_300_100, input_shape, num_classes)\n",
    "\n",
    "original_model: keras.Model = make_lenet()\n",
    "# original_model.summary()\n",
    "# original_model.trainable_variables\n",
    "\n",
    "original_mask_model: keras.Model = mod.create_masked_nn(make_lenet)\n",
    "original_mask_model.summary()\n",
    "# original_mask_model.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(C)\n",
    "reload(train)\n",
    "\n",
    "# Use the original model as a reference\n",
    "loss_fn: tf.keras.losses.Loss = C.LOSS_FUNCTION()\n",
    "accuracy_metric: tf.keras.metrics.Metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "test_loss, test_accuracy = train.test_step(original_model, X_test, Y_test, loss_fn, accuracy_metric)\n",
    "print(f'Test Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(train)\n",
    "\n",
    "# Test that deepcopy is exactly the same as the original model\n",
    "# Copy originals\n",
    "model: keras.Model = copy.deepcopy(original_model)\n",
    "mask_model: keras.Model = copy.deepcopy(original_mask_model)\n",
    "\n",
    "test_loss, test_accuracy = train.test_step(original_model, X_test, Y_test, loss_fn, accuracy_metric)\n",
    "print(f'Test Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(C)\n",
    "reload(train)\n",
    "\n",
    "# Test single step of training\n",
    "\n",
    "# Define the optimizer outside of the function\n",
    "optimizer = C.OPTIMIZER()\n",
    "train_one_step: callable = train.get_train_one_step()\n",
    "accuracy_metric.reset_states()\n",
    "\n",
    "# Copy originals\n",
    "model: keras.Model = copy.deepcopy(original_model)\n",
    "mask_model: keras.Model = copy.deepcopy(original_mask_model)\n",
    "\n",
    "# Sanity Check\n",
    "test_loss, test_accuracy = train.test_step(model, X_test, Y_test, loss_fn, accuracy_metric)\n",
    "print(f'\\nTest Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}\\n')\n",
    "\n",
    "epochs: int = C.TRAINING_EPOCHS\n",
    "\n",
    "train_accuracies: np.array = np.zeros(epochs)\n",
    "test_accuracies: np.array = np.zeros(epochs)\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_loss, train_accuracy = train_one_step(model, mask_model, X_train, Y_train, optimizer)\n",
    "    train_accuracies[i] = train_accuracy\n",
    "\n",
    "    test_loss, test_accuracy = train.test_step(model, X_test, Y_test, loss_fn, accuracy_metric)\n",
    "    test_accuracies[i] = test_accuracy\n",
    "\n",
    "    print(f'Epoch {i + 1} Train Loss: {train_loss:.6f}, Train Accuracy: {train_accuracy:.6f}, Test Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}')\n",
    "\n",
    "print(f'Test Accuracies:')\n",
    "print(test_accuracies)\n",
    "print(f'Training Accuracies:')\n",
    "print(train_accuracies)\n",
    "\n",
    "# Get test parameters\n",
    "accuracy_metric.reset_states()\n",
    "test_loss, test_accuracy = train.test_step(model, X_test, Y_test, loss_fn, accuracy_metric)\n",
    "print(f'\\nTest Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(C)\n",
    "reload(train)\n",
    "\n",
    "# Testing `training_loop` function\n",
    "epochs: int = C.TRAINING_EPOCHS\n",
    "\n",
    "# Copy originals\n",
    "model: keras.Model = copy.deepcopy(original_model)\n",
    "mask_model: keras.Model = copy.deepcopy(original_mask_model)\n",
    "\n",
    "# Sanity Check\n",
    "test_loss, test_accuracy = train.test_step(model, X_test, Y_test, loss_fn, accuracy_metric)\n",
    "print(f'\\nTest Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}\\n')\n",
    "\n",
    "training_round = train.training_loop(0, model, mask_model, dataset.load_and_process_mnist, epochs)\n",
    "\n",
    "print(f'Took {np.sum(training_round.test_accuracies != 0)} / {epochs} epochs')\n",
    "print(f'Ended with a best training accuracy of {np.max(training_round.train_accuracies) * 100:.2f}% and test accuracy of {np.max(training_round.test_accuracies) * 100:.2f}%')\n",
    "\n",
    "print(f'Test Accuracies:')\n",
    "print(training_round.test_accuracies)\n",
    "print(f'Training Accuracies:')\n",
    "print(training_round.train_accuracies)\n",
    "\n",
    "# Get test parameters\n",
    "test_loss, test_accuracy = train.test_step(model, X_test, Y_test, loss_fn, accuracy_metric)\n",
    "print(f'\\nTest Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing `train` function\n",
    "\n",
    "# Copy originals\n",
    "model: keras.Model = copy.deepcopy(original_model)\n",
    "mask_model: keras.Model = copy.deepcopy(original_mask_model)\n",
    "\n",
    "# Sanity Check\n",
    "test_loss, test_accuracy = train.test_step(model, X_test, Y_test, loss_fn, accuracy_metric)\n",
    "print(f'\\nTest Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}\\n')\n",
    "\n",
    "training_round = train.train(0, 0, model, mask_model, dataset.load_and_process_mnist, batch_size=C.BATCH_SIZE)\n",
    "\n",
    "print(f'\\nTook {np.sum(training_round.test_accuracies != 0)} / {C.TRAINING_EPOCHS} epochs')\n",
    "print(f'Ended with a best training accuracy of {np.max(training_round.train_accuracies) * 100:.2f}% and test accuracy of training accuracy of {np.max(training_round.test_accuracies) * 100:.2f}%')\n",
    "\n",
    "print(f'Test Accuracies:')\n",
    "print(training_round.test_accuracies)\n",
    "print(f'Training Accuracies:')\n",
    "print(training_round.train_accuracies)\n",
    "\n",
    "# Get test parameters\n",
    "test_loss, test_accuracy = train.test_step(model, X_test, Y_test, loss_fn, accuracy_metric)\n",
    "print(f'\\nTest Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the model back\n",
    "loaded_model: keras.Model = mod.load_model(0, 0)\n",
    "\n",
    "# Get test parameters\n",
    "test_loss, test_accuracy = train.test_step(loaded_model, X_test, Y_test, loss_fn, accuracy_metric)\n",
    "print(f'\\nTest Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Nonzero parameters after training but before pruning:')\n",
    "print(utils.count_total_and_nonzero_params(model)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the model back\n",
    "loaded_model: keras.Model = mod.load_model(0, 0)\n",
    "target_sparsity = 0.5\n",
    "\n",
    "# Get test parameters\n",
    "test_loss, test_accuracy = train.test_step(loaded_model, X_test, Y_test, loss_fn, accuracy_metric)\n",
    "print(f'\\nTest Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}')\n",
    "\n",
    "sparse_model = copy.deepcopy(loaded_model)\n",
    "\n",
    "total, nonzero = utils.count_total_and_nonzero_params(loaded_model)\n",
    "print(f'Total Params: {total}, Nonzero Params: {nonzero}')\n",
    "print('Pruning')\n",
    "pruning.prune(sparse_model, pruning.low_magnitude_pruning, target_sparsity)\n",
    "\n",
    "total2, nonzero2 = utils.count_total_and_nonzero_params(sparse_model)\n",
    "print(f'Total Params: {total}, Nonzero Params: {nonzero}')\n",
    "\n",
    "assert total2 == total\n",
    "assert nonzero2 == nonzero // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mod)\n",
    "reload(rewind)\n",
    "    \n",
    "model: keras.Model = copy.deepcopy(original_model)\n",
    "mask_model: keras.Model = copy.deepcopy(original_mask_model)\n",
    "original_weights = model.get_weights()\n",
    "\n",
    "rewind_to_original_weights: callable = functools.partial(rewind.rewind_to_original_init, 0)\n",
    "rewind_to_random_weights: callable = functools.partial(rewind.rewind_to_random_init, 0, tf.initializers.GlorotUniform())\n",
    "rewind.rewind_model_weights(model, mask_model, rewind_to_random_weights)\n",
    "\n",
    "print(original_weights[0][0][:10])\n",
    "print(model.get_weights()[0][0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mod)\n",
    "reload(pruning)\n",
    "\n",
    "model: keras.Model = copy.deepcopy(original_model)\n",
    "mask_model: keras.Model = copy.deepcopy(original_mask_model)\n",
    "\n",
    "# Asserting that every array in the mask model's weights are 1s\n",
    "for layer in mask_model.layers:\n",
    "    for weights in layer.get_weights():\n",
    "        assert np.all(weights == 1), \"Error: Not all elements in mask model's weights are 1s after updating masks\"\n",
    "\n",
    "pruning.update_masks(model, mask_model)\n",
    "\n",
    "# Asserting that every array in the mask model's weights are still 1s\n",
    "for layer in mask_model.layers:\n",
    "    for weights in layer.get_weights():\n",
    "        assert np.all(weights == 1), \"Error: Not all elements in mask model's weights are 1s after updating masks\"\n",
    "        \n",
    "pruning.prune(model, pruning.low_magnitude_pruning, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mod)\n",
    "reload(pruning)\n",
    "reload(utils)\n",
    "\n",
    "# Pruning Parameters\n",
    "first_step_pruning: float = 0.2\n",
    "target_sparsity: float = 0.8\n",
    "make_lenet: callable = functools.partial(mod.create_lenet_300_100, input_shape, num_classes)\n",
    "\n",
    "global_pruning: bool = False\n",
    "\n",
    "# Hardcoded for now until actual experiment code is done\n",
    "for seed in range(1):\n",
    "    utils.set_seed(seed)\n",
    "    # Make models and save them\n",
    "    model: keras.Model = make_lenet()\n",
    "    mask_model: keras.Model = mod.create_masked_nn(make_lenet)   \n",
    "    mod.save_model(model, seed, 0, initial=True)\n",
    "    mod.save_model(mask_model, seed, 0, masks=True, initial=True)\n",
    "    \n",
    "    # Create the rewind rule\n",
    "    rewind_to_original_weights: callable = functools.partial(rewind.rewind_to_original_init, seed)\n",
    "    \n",
    "    # Get the pruning percents and iterate over them \n",
    "    pruning_percents: list[float] = pruning.get_sparsity_percents(model, first_step_pruning, target_sparsity)\n",
    "    for pruning_step, sparsity in enumerate(pruning_percents):\n",
    "        # Retrieve original model weights\n",
    "        original_weights: list[np.ndarray] = mod.load_model(seed, initial=True)\n",
    "        \n",
    "        # Prune the model to the new sparsity\n",
    "        pruning.prune(model, pruning.low_magnitude_pruning, sparsity, global_pruning=global_pruning)\n",
    "        \n",
    "        # Update mask model\n",
    "        pruning.update_masks(model, mask_model)\n",
    "        \n",
    "        # Reset unpruned weights to original values.\n",
    "        rewind.rewind_model_weights(model, mask_model, rewind_to_original_weights)\n",
    "        \n",
    "        loss_fn: tf.keras.losses.Loss = C.LOSS_FUNCTION()\n",
    "        accuracy_metric: tf.keras.metrics.Metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "        # Sanity Check\n",
    "        test_loss, test_accuracy = train.test_step(model, X_test, Y_test, loss_fn, accuracy_metric)\n",
    "        print(f'\\nModel {seed}\\nStarting Test Loss: {test_loss:.6f}, Test Accuracy: {test_accuracy:.6f}\\n')\n",
    "\n",
    "        training_round = train.train(seed, pruning_step, model, mask_model, dataset.load_and_process_mnist, batch_size=C.BATCH_SIZE)\n",
    "\n",
    "        print(f'\\nTook {np.sum(training_round.test_accuracies != 0)} / {C.TRAINING_EPOCHS} epochs')\n",
    "        print(f'Ended with a best training accuracy of {np.max(training_round.train_accuracies) * 100:.2f}% and test accuracy of training accuracy of {np.max(training_round.test_accuracies) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(experiment)\n",
    "reload(pruning)\n",
    "reload(rewind)\n",
    "reload(train)\n",
    "\n",
    "# Pruning Parameters\n",
    "first_step_pruning: float = 0.2\n",
    "target_sparsity: float = 0.05\n",
    "make_lenet: callable = functools.partial(mod.create_lenet_300_100, input_shape, num_classes)\n",
    "\n",
    "global_pruning: bool = False\n",
    "sparsities: list[float] = pruning.get_sparsity_percents(model, first_step_pruning, target_sparsity)\n",
    "experiment_data: experiment.ExperimentData = experiment.run_iterative_pruning_experiment(\n",
    "    0, \n",
    "    make_lenet, \n",
    "    dataset.load_and_process_mnist,\n",
    "    sparsities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(experiment)\n",
    "reload(train)\n",
    "reload(utils)\n",
    "\n",
    "for step_index in range(len(sparsities)):\n",
    "    round = experiment_data.pruning_rounds[step_index]\n",
    "    print(f'{round.get_sparsity():.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
